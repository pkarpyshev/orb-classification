{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7030819b",
   "metadata": {},
   "source": [
    "## NN Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4430b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67746950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuke/.cache/pypoetry/virtualenvs/orb-classification-iGtAwsn7-py3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "PYTHON_PATHS = [\"..\"]\n",
    "import sys\n",
    "for path in PYTHON_PATHS:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from classifier.resnet18 import Resnet18Model\n",
    "from data_loader.orb_features_data_module import ORBFeaturesDataModule\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d433e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'hidden_sizes' and 'out_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mResnet18Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfreeze_backbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'hidden_sizes' and 'out_size'"
     ]
    }
   ],
   "source": [
    "model = Resnet18Model(nn.Sequential(nn.Linear(512, 512),\n",
    "                                           nn.Linear(512, 512),\n",
    "                                           nn.Linear(512, 2)\n",
    "                                          ),\n",
    "                             freeze_backbone=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5612bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_module_params = {'root': \"/home/alena/Documents/omni-vision/dataset\", \n",
    "                  'dataset': [\"dataset_2_cam_0\",\n",
    "                              \"dataset_2_cam_1\",\n",
    "                              \"dataset_2_cam_2\",\n",
    "                              \"dataset_2_cam_3\",\n",
    "                              \"dataset_2_cam_5\",\n",
    "                              \"dataset_3_cam_0\",\n",
    "                              \"dataset_3_cam_1\",\n",
    "                              \"dataset_3_cam_2\",\n",
    "                              \"dataset_3_cam_3\",\n",
    "                              \"dataset_3_cam_5\"\n",
    "                             ],\n",
    "                  'classification_threshold': 300,\n",
    "                  'transform': model.transform,\n",
    "                  'batch_size': 128+32,\n",
    "                  'shuffle': True,\n",
    "                  'num_workers': 6,\n",
    "                  'num_val': 1000,\n",
    "                  \"num_test\": 1000,}\n",
    "\n",
    "datamodule = ORBFeaturesDataModule(**dataset_module_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1, log_every_n_steps=1, max_epochs=8)\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from data_loader.orb_features_dataset import ORBFeaturesDataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {'root': \"/home/alena/Documents/omni-vision/dataset\", \n",
    "                  'datasets': [\n",
    "#                               \"dataset_1_cam_0\",\n",
    "                              \"dataset_1_cam_1\",\n",
    "                              \"dataset_1_cam_2\",\n",
    "                              \"dataset_1_cam_3\",\n",
    "                              \"dataset_1_cam_5\"\n",
    "                             ],\n",
    "                  'classification_threshold': 300,\n",
    "                  'transform': model.transform,\n",
    "                  'combine_data': False\n",
    "                 }\n",
    "\n",
    "dataset = ORBFeaturesDataset(**dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c91107",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.images_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_img(img_path, tranform):\n",
    "    image = read_image(img_path)[None, ...]\n",
    "    return tranform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for d in tqdm(dataset.images_list):\n",
    "    preds= []\n",
    "    \n",
    "    for img_path in d:\n",
    "        img = read_dataset_img(img_path, model.transform)\n",
    "        preds.append(torch.nn.functional.softmax(model.forward(img), dim=1).detach().cpu().numpy())\n",
    "        \n",
    "    predictions.append(preds)\n",
    "    \n",
    "labels = dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for p in predictions:\n",
    "    pred_proba = np.squeeze(np.array(p), axis=1)\n",
    "    pred.append(np.argmax(pred_proba, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068da14a",
   "metadata": {},
   "source": [
    "## Camera Switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d04fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(np.array(predictions[0][:5]), axis=1)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e098ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argpartition(np.squeeze(np.array(predictions[0][:5]), axis=1)[:, 1], -2)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cefe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def choose_two_best(valid_cams, cams_proba, num_cams=2):\n",
    "#     if sum(valid_cams) == num_cams:\n",
    "#         idx = np.where(valid_cams == True)\n",
    "#         return idx[0], idx[1]\n",
    "    \n",
    "#     elif sum(valid_cams) > num_cams:\n",
    "#         # find indexes of two maximal values in probabilities class 1\n",
    "#         idx = np.argpartition(cam_proba[:, 1], -num_cams)[-num_cams:]\n",
    "#         return idx[0], idx[1]\n",
    "    \n",
    "#     elif sum(valid_cams) < 2:\n",
    "#         # find indexes of two minims values in probabilities class 0\n",
    "#         idx = np.argpartition(cam_proba[:, 1], -2)[-2:]\n",
    "#         return idx[0], idx[1]\n",
    "        \n",
    "\n",
    "def get_valid_cams(idx, pred, pred_proba, num_cams=2):\n",
    "    valid_cams = [p[idx] for p in pred]\n",
    "    cams_proba = np.squeeze([p[idx] for p in pred_proba], axis=1)\n",
    "    \n",
    "#     print(cams_proba)\n",
    "    cam_ids = np.argpartition(cams_proba[:, 1], -2)[-2:]\n",
    "\n",
    "    return cam_ids[0], cam_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef523e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred[0].shape[0]\n",
    "cameras = []\n",
    "\n",
    "for i in range(N):\n",
    "    cam1, cam2 = get_valid_cams(i, pred, predictions)\n",
    "    cameras.append([cam1, cam2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f39ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.features_list[cameras[0], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1_data = []\n",
    "cam2_data = []\n",
    "\n",
    "for i in range(len(cameras)):\n",
    "    cam1_data.append(dataset.features_list[cameras[i][0]][i])\n",
    "    cam2_data.append(dataset.features_list[cameras[i][1]][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e03bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2282673",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "PYTHON_PATHS = [\"../orb-classification/\"]\n",
    "import sys\n",
    "for path in PYTHON_PATHS:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "\n",
    "from data_loader.orb_features_dataset import ORBFeaturesDataset\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params = {'root': \"/home/alena/Documents/omni-vision/dataset\", \n",
    "#                   'datasets': [\n",
    "#                               \"dataset_2_cam_0\",\n",
    "#                               \"dataset_2_cam_1\",\n",
    "#                               \"dataset_2_cam_2\",\n",
    "#                              #\"dataset_1_cam_0\",\n",
    "#                              ],\n",
    "#                   'classification_threshold': 300,\n",
    "#                   'transform': None,\n",
    "#                   'combine_data': False\n",
    "#                  }\n",
    "\n",
    "# dataset = ORBFeaturesDataset(**dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d762a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset.labels)):\n",
    "    plt.subplots(figsize=(8, 2))\n",
    "    plt.title(f\"Number of ORB features on sequence{0}, camera{i}\")\n",
    "    plt.xlabel(\"frame num\")\n",
    "    plt.ylabel(\"num features\")\n",
    "    plt.plot(dataset.features_list[i])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_coeff = 20\n",
    "\n",
    "def running_mean(x, N=running_mean_coeff):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "cam_features = []\n",
    "for i in range(len(dataset.labels)):\n",
    "    cam_features.append(running_mean(dataset.features_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset.labels)):\n",
    "    plt.subplots(figsize=(8, 2))\n",
    "    plt.title(f\"Number of ORB features on sequence{0}, camera{i}\")\n",
    "    plt.xlabel(\"frame num\")\n",
    "    plt.ylabel(\"num features\")\n",
    "    plt.plot(dataset.features_list[i])\n",
    "    plt.plot(cam_features[i])\n",
    "    plt.show();\n",
    "\n",
    "    \n",
    "cam2_data_s = running_mean(cam2_data)\n",
    "plt.subplots(figsize=(8, 2))\n",
    "plt.title(f\"Our approach with camera switch\")\n",
    "plt.xlabel(\"frame num\")\n",
    "plt.ylabel(\"num features\")\n",
    "plt.plot(cam2_data)\n",
    "plt.plot(cam2_data_s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16, 6))\n",
    "plt.title(f\"Number of ORB features on sequence{0}, camera{i}\")\n",
    "plt.xlabel(\"frame num\")\n",
    "plt.ylabel(\"num features\")\n",
    "plt.plot(cam_features[0])\n",
    "plt.plot(cam_features[1])\n",
    "plt.plot(cam_features[2])\n",
    "plt.plot(cam2_data_s, linewidth=3, color='k')\n",
    "plt.legend([\"cam0\", \"cam1\", \"cam2\", \"ours\"])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c='rgbyk'\n",
    "for i in range(len(dataset.labels)):\n",
    "    plt.subplots(figsize=(8, 2))\n",
    "    plt.title(f\"Number of ORB features on sequence{0}, camera{i}\")\n",
    "    plt.xlabel(\"frame num\")\n",
    "    plt.ylabel(\"num features\")\n",
    "    plt.plot(cam_features[i], color=c[i])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3443fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cam in cameras:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "dataset_size = len(dataset.labels)\n",
    "# x = np.linspace(0, dataset_size, dataset_size)\n",
    "# y = dataset.features_list[0]\n",
    "\n",
    "for i in range(dataset_size):\n",
    "    fig = go.Figure()\n",
    "    y = dataset.features_list[i][:500]\n",
    "    x = np.linspace(0, y.shape[0], y.shape[0])\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=x, y=y))\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc792b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
